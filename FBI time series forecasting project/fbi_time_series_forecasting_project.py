# -*- coding: utf-8 -*-
"""FBI time series forecasting project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ssDvBjo79r5KTFLk2Ml--XbU3v6DBks-

# **Project title- FBI time series forecasting project**

# **Project Summary:**

In this project, we are going to analyzes where and when crimes happen, and predicts how many crimes might happen in the future using data science and time series techniques.


*   Understand trends and patterns in crime over time and space.

*   Visualize where crimes are happening using maps.

*   Forecast future crime incidents using time series models (e.g., SARIMA).

#  https://github.com/tar697/FBI-time-series-forecasting

**Import required libraries**
"""

import pandas as pd #  For handling and manipulating data.
import numpy as np  #  For handling and manipulating data.
import matplotlib.pyplot as plt # For data visualization
import seaborn as sns # For data visualization
import geopandas as gpd # For geospatial data and mapping
from shapely.geometry import Point
import statsmodels.api as sm # For statistical time series modeling (e.g., SARIMA)
from sklearn.model_selection import train_test_split #Split data for training/testing

"""After importing all the necessary libraries , we will load  the data file into a DataFrame. Converts string dates into real datetime objects, so that we can do time-based analysis and forecasting


"""

# Load dataset
df = pd.read_excel("/content/Train.xlsx")

# Convert date to datetime and extract time features
df['Date'] = pd.to_datetime(df['Date'])
df['YEAR'] = df['Date'].dt.year
df['MONTH'] = df['Date'].dt.month
df.head()

"""**Data cleaning and preprocessing**"""

# Drop rows with missing geo-coordinates
rows, columns = df.shape
print("Rows:", rows)
print("Columns:", columns)
df.dropna(subset=['Date', 'Latitude', 'Longitude'], inplace=True)
# Create 'Month_Year' for monthly grouping
df['Month_Year'] = df['Date'].dt.to_period('M')

"""**Counts total number of records (crimes) for each month.**"""

monthly_counts = df.groupby('Month_Year').size()
print(monthly_counts)
monthly_counts.plot(kind='line', figsize=(12, 4), title="Monthly Crime Trend")
plt.ylabel("Crime Count")
plt.grid(True)
plt.show()

"""**Geospatial Visualization**"""

#Combines Longitude and Latitude into Point geometries.
geometry = [Point(xy) for xy in zip(df['Longitude'], df['Latitude'])]
# Converts the original DataFrame into a GeoDataFrame, adding spatial data support
geo_df = gpd.GeoDataFrame(df, geometry=geometry)

"""**Time Series Forecasting with SARIMA**"""

# aggregate the total number of incidents per month from the dataset df
monthly_total = df.resample('ME', on='Date').size()
# SARIMA model fitting
model = sm.tsa.statespace.SARIMAX(monthly_total,
                                  order=(1,1,1),
                                  seasonal_order=(1,1,1,12),
                                  enforce_stationarity=False,
                                  enforce_invertibility=False)
results = model.fit()

"""**Forecasting the future**"""

# Forecasts crime counts for the next 12 months.
forecast = results.get_forecast(steps=12)
conf_int = forecast.conf_int() # Calculates a 95% confidence interval for each prediction.

"""**Plot Forecast with Confidence Intervals**"""

plt.figure(figsize=(12, 5))
monthly_total.plot(label='Observed', color='blue')
forecast.predicted_mean.plot(label='Forecast', color='green')
plt.fill_between(conf_int.index,
                 conf_int.iloc[:, 0],
                 conf_int.iloc[:, 1], color='lightgreen', alpha=0.4)
plt.xlabel('Date')
plt.ylabel('Crime Incidents')
plt.title('SARIMA Forecast of Crime Incidents')
plt.legend()
plt.tight_layout()
plt.show()

test_df = pd.read_csv('/content/Test (2).csv')
test_df['Date'] = pd.to_datetime(test_df[['YEAR', 'MONTH']].assign(DAY=1))
test_dates = test_df['Date'].sort_values().unique()

# Forecast using SARIMA model for the exact number of months in the test set
n_forecast_months = len(test_dates)
forecast_results = results.get_forecast(steps=n_forecast_months)

# Create a forecast index from the last training date
forecast_index = pd.date_range(start=monthly_total.index[-1] + pd.DateOffset(months=1),
                               periods=n_forecast_months,
                               freq='MS')

# Build forecast DataFrame
forecast_df = pd.DataFrame({
    'Date': forecast_index,
    'Predicted_Incidents': forecast_results.predicted_mean.values
})

# Add 'YEAR' and 'MONTH' to the forecast for merging
forecast_df['YEAR'] = forecast_df['Date'].dt.year
forecast_df['MONTH'] = forecast_df['Date'].dt.month

# Merge with original test_df on YEAR and MONTH
test_df = pd.merge(test_df, forecast_df[['YEAR', 'MONTH', 'Predicted_Incidents']],
                   on=['YEAR', 'MONTH'], how='left')
test_df.head()

# Step 1: Aggregate monthly actual incident counts
monthly_actual_full = df.groupby(['YEAR', 'MONTH']).size().reset_index(name='Actual_Incidents')

# Step 2: Convert to datetime
monthly_actual_full['Date'] = pd.to_datetime(
    monthly_actual_full['YEAR'].astype(str) + '-' + monthly_actual_full['MONTH'].astype(str).str.zfill(2)
)

# Step 3: Sort by date
monthly_actual_full = monthly_actual_full.sort_values('Date')

# Step 4: Select the last 18 months only (matching your forecast length)
monthly_actual = monthly_actual_full.tail(18).copy()

# Step 5: Add forecasted values
monthly_actual['Forecasted_Incidents'] = forecast_results.predicted_mean.values

# Step 6: Plot

plt.figure(figsize=(12, 6))
plt.plot(monthly_actual['Date'], monthly_actual['Actual_Incidents'], label='Actual', marker='o')
plt.plot(monthly_actual['Date'], monthly_actual['Forecasted_Incidents'], label='Forecasted', marker='x')
plt.xlabel('Time (YYYY-MM)')
plt.ylabel('Number of Incidents')
plt.title('Actual vs Forecasted Incident Counts')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()